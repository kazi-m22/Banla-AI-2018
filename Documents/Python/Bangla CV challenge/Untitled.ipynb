{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training-k', 'training-c', 'training-e.csv', 'training-b.csv', 'training-i', 'training-e', 'testing-c', 'training-b', 'testing-g', 'training-c.csv', 'training-d.csv', 'testing-auga', 'training-h', 'training-a.csv', 'testing-e', 'training-g', 'testing-a', 'testing-b', 'training-f', 'training-d', 'testing-f', 'training-j', 'testing-augc', 'testing-d', 'training-a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation,Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_WIDTH=20 # Width of figure\n",
    "HEIGHT_PER_ROW=3 # Height of each row when showing a figure which consists of multiple rows\n",
    "RESIZE_DIM= 64# The images will be resized to 28x28 pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=os.path.join('.','input')\n",
    "paths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\n",
    "paths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\n",
    "paths_train_g=glob.glob(os.path.join(data_dir,'training-g','*.png'))\n",
    "paths_train_h=glob.glob(os.path.join(data_dir,'training-h','*.png'))\n",
    "paths_train_k=glob.glob(os.path.join(data_dir,'training-k','*.png'))\n",
    "paths_train_l=glob.glob(os.path.join(data_dir,'training-l','*.png'))\n",
    "\n",
    "\n",
    "paths_train_all=paths_train_a+paths_train_c+paths_train_g+paths_train_h+paths_train_k+paths_train_l\n",
    "\n",
    "\n",
    "paths_test_all=glob.glob(os.path.join(data_dir,'testing-g','*.png'))\n",
    "\n",
    "path_label_train_a=os.path.join(data_dir,'training-a.csv')\n",
    "path_label_train_c=os.path.join(data_dir,'training-c.csv')\n",
    "path_label_train_g=os.path.join(data_dir,'training-b.csv')\n",
    "path_label_train_h=os.path.join(data_dir,'training-b.csv')\n",
    "path_label_train_k=os.path.join(data_dir,'training-a.csv')\n",
    "path_label_train_l=os.path.join(data_dir,'training-d.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(path):\n",
    "    # seperates the key of an image from the filepath\n",
    "    key=path.split(sep=os.sep)[-1]\n",
    "    return key\n",
    "\n",
    "def get_data(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img):\n",
    "        img=cv2.imread(path,cv2.IMREAD_COLOR) # images loaded in color (BGR)\n",
    "        #img = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # cnahging colorspace to GRAY\n",
    "        if resize_dim is not None:\n",
    "            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n",
    "        #X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n",
    "        gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "        img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "        thresh = 200\n",
    "        maxValue = 255\n",
    "        #th, img = cv2.threshold(img, thresh, maxValue, cv2.THRESH_BINARY);\n",
    "        ret,img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename') \n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_group(X,y,y_pred=None,n_per_row=10,phase='processed'):\n",
    "    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n",
    "    Args:\n",
    "        X: images\n",
    "        y: categorical true labels\n",
    "        y_pred: predicted class probabilities\n",
    "        n_per_row: number of images per row to be plotted\n",
    "        phase: If the images are plotted after resizing, pass 'processed' to phase argument. \n",
    "            It will plot the image and its true label. If the image is plotted after prediction \n",
    "            phase, pass predicted class probabilities to y_pred and 'prediction' to the phase argument. \n",
    "            It will plot the image, the true label, and it's top 3 predictions with highest probabilities.\n",
    "    '''\n",
    "    n_sample=len(X)\n",
    "    img_dim=X.shape[1]\n",
    "    j=np.ceil(n_sample/n_per_row)\n",
    "    fig=plt.figure(figsize=(FIG_WIDTH,HEIGHT_PER_ROW*j))\n",
    "    for i,img in enumerate(X):\n",
    "        plt.subplot(j,n_per_row,i+1)\n",
    "#         img_sq=np.squeeze(img,axis=2)\n",
    "#         plt.imshow(img_sq,cmap='gray')\n",
    "        plt.imshow(img)\n",
    "        if phase=='processed':\n",
    "            plt.title(np.argmax(y[i]))\n",
    "        if phase=='prediction':\n",
    "            top_n=3 # top 3 predictions with highest probabilities\n",
    "            ind_sorted=np.argsort(y_pred[i])[::-1]\n",
    "            h=img_dim+4\n",
    "            for k in range(top_n):\n",
    "                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n",
    "                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n",
    "                h+=4\n",
    "            if y is not None:\n",
    "                plt.text(img_dim/2, -4, 'true label: {}'.format(np.argmax(y[i])), \n",
    "                         horizontalalignment='center',verticalalignment='center')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions,keys,path):\n",
    "    result = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=['label'],\n",
    "        index=keys\n",
    "        )\n",
    "    result.index.name='key'\n",
    "    result.to_csv(path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 19702/19702\n",
      "processed 24298/24298\n",
      "processed 359/359\n",
      "processed 359/359\n",
      "processed 19702/19702\n",
      "processed 10908/10908\n"
     ]
    }
   ],
   "source": [
    "X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_g,y_train_g=get_data(paths_train_g,path_label_train_g,resize_dim=RESIZE_DIM)\n",
    "X_train_h,y_train_h=get_data(paths_train_h,path_label_train_h,resize_dim=RESIZE_DIM)\n",
    "X_train_k,y_train_k=get_data(paths_train_k,path_label_train_k,resize_dim=RESIZE_DIM)\n",
    "X_train_l,y_train_l=get_data(paths_train_l,path_label_train_l,resize_dim=RESIZE_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75328, 64, 64), (75328, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all=np.concatenate((X_train_a,X_train_c,X_train_g,X_train_h, X_train_k,X_train_l),axis=0)\n",
    "y_train_all=np.concatenate((y_train_a,y_train_c,y_train_g,y_train_h,y_train_k,y_train_l),axis=0)\n",
    "X_train_all.shape, y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1/20\r",
      "processed 2/20\r",
      "processed 3/20\r",
      "processed 4/20\r",
      "processed 5/20\r",
      "processed 6/20\r",
      "processed 7/20\r",
      "processed 8/20\r",
      "processed 9/20\r",
      "processed 10/20\r",
      "processed 11/20\r",
      "processed 12/20\r",
      "processed 13/20\r",
      "processed 14/20\r",
      "processed 15/20\r",
      "processed 16/20\r",
      "processed 17/20\r",
      "processed 18/20\r",
      "processed 19/20\r",
      "processed 20/20\n"
     ]
    }
   ],
   "source": [
    "X_test_g=get_data(paths_test_all,resize_dim=RESIZE_DIM)\n",
    "X_test_all=X_test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tshow_all=X_test_all\n",
    "X_tshow_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = X_train_all.reshape(X_train_all.shape[0],64, 64,1).astype('float32')\n",
    "X_test_all = X_test_all.reshape(X_test_all.shape[0],64, 64,1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75328, 64, 64, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = X_train_all / 255\n",
    "X_test_all = X_test_all / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=list(range(len(X_train_all)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ind=int(len(indices)*0.80)\n",
    "# train data\n",
    "X_train=X_train_all[indices[:ind]] \n",
    "y_train=y_train_all[indices[:ind]]\n",
    "# validation data\n",
    "X_val=X_train_all[indices[-(len(indices)-ind):]] \n",
    "y_val=y_train_all[indices[-(len(indices)-ind):]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    #    featurewise_center=True,\n",
    "   #     samplewise_center=True,\n",
    "  #      featurewise_std_normalization=True,\n",
    " #       samplewise_std_normalization=True,\n",
    "#        zca_whitening=True, \n",
    "#        zca_epsilon=1e-06,\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "#        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    " #       horizontal_flip=True,\n",
    "    #    fill_mode='nearest'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen.fit(X_train)\n",
    "datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "def my_model(img_size=64,channels=1):\n",
    "    model = Sequential()\n",
    "    input_shape = (img_size,img_size,channels)\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    optmzr = SGD(lr=0.1, clipnorm=5.)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
    "    #model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 128)       36992     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1048640   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,145,578\n",
      "Trainable params: 2,145,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = my_model()\n",
    "model.summary()\n",
    "path_model='model_filter.h5' # save model at this location after each epoch\n",
    "# K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "model=my_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-4) # set the learning rate\n",
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60262 samples, validate on 15066 samples\n",
      "Epoch 1/1\n",
      "60262/60262 [==============================] - 52s 868us/step - loss: 0.2129 - acc: 0.9273 - val_loss: 0.2032 - val_acc: 0.9348\n"
     ]
    }
   ],
   "source": [
    "h=model.fit(x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=256, \n",
    "            epochs=1,\n",
    "            verbose=1, \n",
    "            validation_data=(X_val,y_val),\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(filepath=path_model),\n",
    "            ]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = model.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[np.argmax(pred) for pred in predictions_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[get_key(path) for path in paths_test_all ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(predictions=labels,keys=keys,path='box_pred_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
